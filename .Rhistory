return(p_SOI_allq_gen)
}
test_plot <- allq_plotting_fun(label_shift = 1, title_in = "Work Environment Average Scores, Mean & 95% Confidence Interval", data_in = SOI_allq_Env , picname_in = "1Statewide_WorkEnvironment.jpg")
print(test_plot)
allq_plotting_fun <- function(label_shift, title_in, data_in, picname_in){
# Plot results  - basic plot
p_SOI_allq_gen<- ggplot(SOI_allq_Env, aes(x=variable, y=Mean, fill=SurveyYear.f)) +
geom_bar(stat="identity", color="black",
position=position_dodge()) +
geom_errorbar(aes(ymin=Mean-2*SD, ymax=Mean+2*SD), width=.2,
position=position_dodge(.9))
# Cleaned up bar plot
p_SOI_allq_gen <- p_SOI_allq_gen+labs(title=title_in, x="Survey Question", y = "Average Score")+
theme_minimal()+scale_fill_discrete(name = "Survey Year") +
theme(axis.text.x=element_text(angle=40, hjust=1, size = 7))+
geom_label(data = SOI_allq_Env, aes(x=variable, y=Mean-label_shift, label=round(Mean, digits=2)), position = position_dodge(0.9), label.padding = unit(0.1, "lines"))
print(p_SOI_allq_gen)
picname <- picname_in
ggsave(picname, plot = last_plot(), device = "jpeg", path = NULL, width = 12, height = 6, units = "in", dpi = 600, limitsize = TRUE)
return(p_SOI_allq_gen)
}
test_plot <- allq_plotting_fun(label_shift = 1, title_in = "Work Environment Average Scores, Mean & 95% Confidence Interval", data_in = SOI_allq_Env , picname_in = "1Statewide_WorkEnvironment.jpg")
test_plot <- allq_plotting_fun(label_shift = 1, title_in = "Work Environment Average Scores, Mean & 95% Confidence Interval", data_in = SOI_allq_Env , picname_in = "1Statewide_WorkEnvironment.jpg")
allq_plotting_fun <- function(label_shift, title_in, data_in, picname_in){
# Plot results  - basic plot
p_SOI_allq_gen<- ggplot(SOI_allq_Env, aes(x=variable, y=Mean, fill=SurveyYear.f)) +
geom_bar(stat="identity", color="black",
position=position_dodge()) +
geom_errorbar(aes(ymin=Mean-2*SD, ymax=Mean+2*SD), width=.2,
position=position_dodge(.9))
# Cleaned up bar plot
p_SOI_allq_gen <- p_SOI_allq_gen+labs(title=title_in, x="Survey Question", y = "Average Score")+
theme_minimal()+scale_fill_discrete(name = "Survey Year") +
theme(axis.text.x=element_text(angle=40, hjust=1, size = 7))+
geom_label(data = SOI_allq_Env, aes(x=variable, y=Mean-label_shift, label=round(Mean, digits=2)), position = position_dodge(0.9), label.padding = unit(0.1, "lines"))
print(p_SOI_allq_gen)
picname <- picname_in
ggsave(picname, plot = last_plot(), device = "jpeg", path = NULL, width = 12, height = 6, units = "in", dpi = 600, limitsize = TRUE)
}
test_plot <- allq_plotting_fun(label_shift = 1, title_in = "Work Environment Average Scores, Mean & 95% Confidence Interval", data_in = SOI_allq_Env , picname_in = "1Statewide_WorkEnvironment.jpg")
print(test_plot)
allq_plotting_fun <- function(label_shift, title_in, data_in, picname_in){
# Plot results  - basic plot
p_SOI_allq_gen<- ggplot(data_in, aes(x=variable, y=Mean, fill=SurveyYear.f)) +
geom_bar(stat="identity", color="black",
position=position_dodge()) +
geom_errorbar(aes(ymin=Mean-2*SD, ymax=Mean+2*SD), width=.2,
position=position_dodge(.9))
# Cleaned up bar plot
p_SOI_allq_gen <- p_SOI_allq_gen+labs(title=title_in, x="Survey Question", y = "Average Score")+
theme_minimal()+scale_fill_discrete(name = "Survey Year") +
theme(axis.text.x=element_text(angle=40, hjust=1, size = 7))+
geom_label(data = data_in, aes(x=variable, y=Mean-label_shift, label=round(Mean, digits=2)), position = position_dodge(0.9), label.padding = unit(0.1, "lines"))
print(p_SOI_allq_gen)
picname <- picname_in
ggsave(picname, plot = last_plot(), device = "jpeg", path = NULL, width = 12, height = 6, units = "in", dpi = 600, limitsize = TRUE)
return(p_SOI_allq_gen)
}
test_plot <- allq_plotting_fun(label_shift = 1, title_in = "Work Environment Average Scores, Mean & 95% Confidence Interval", data_in = SOI_allq_Env , picname_in = "1Statewide_WorkEnvironment.jpg")
print(test_plot)
allq_plotting_fun <- function(label_shift, title_in, data_in, picname_in){
# Plot results  - basic plot
p_SOI_allq_gen<- ggplot(data_in, aes(x=variable, y=Mean, fill=SurveyYear.f)) +
geom_bar(stat="identity", color="black",
position=position_dodge()) +
geom_errorbar(aes(ymin=Mean-2*SD, ymax=Mean+2*SD), width=.2,
position=position_dodge(.9))
# Cleaned up bar plot
p_SOI_allq_gen <- p_SOI_allq_gen+labs(title=title_in, x="Survey Question", y = "Average Score")+
theme_minimal()+scale_fill_discrete(name = "Survey Year") +
theme(axis.text.x=element_text(angle=40, hjust=1, size = 7))+
geom_label(data = data_in, aes_string(x=variable, y=Mean-label_shift, label=round(Mean, digits=2)), position = position_dodge(0.9), label.padding = unit(0.1, "lines"))
print(p_SOI_allq_gen)
picname <- picname_in
ggsave(picname, plot = last_plot(), device = "jpeg", path = NULL, width = 12, height = 6, units = "in", dpi = 600, limitsize = TRUE)
return(p_SOI_allq_gen)
}
test_plot <- allq_plotting_fun(label_shift = 1, title_in = "Work Environment Average Scores, Mean & 95% Confidence Interval", data_in = SOI_allq_Env , picname_in = "1Statewide_WorkEnvironment.jpg")
# Plot results - Work Environment - basic plot
p_SOI_allq_Env<- ggplot(SOI_allq_Env, aes_string(x=variable, y=Mean, fill=SurveyYear.f)) +
geom_bar(stat="identity", color="black",
position=position_dodge()) +
geom_errorbar(aes(ymin=Mean-2*SD, ymax=Mean+2*SD), width=.2,
position=position_dodge(.9))
# Plot results - Work Environment - basic plot
p_SOI_allq_Env<- ggplot(SOI_allq_Env, aes_string(x="variable", y="Mean", fill="SurveyYear.f")) +
geom_bar(stat="identity", color="black",
position=position_dodge()) +
geom_errorbar(aes(ymin=Mean-2*SD, ymax=Mean+2*SD), width=.2,
position=position_dodge(.9))
# Cleaned up bar plot
p_SOI_allq_Env <- p_SOI_allq_Env+labs(title="Work Environment Average Scores, Mean & 95% Confidence Interval", x="Survey Question", y = "Average Score")+
theme_minimal()+scale_fill_discrete(name = "Survey Year") +
theme(axis.text.x=element_text(angle=40, hjust=1, size = 7))+
geom_label(data = SOI_allq_Env, aes(x=variable, y=Mean-1, label=round(Mean, digits=2)), position = position_dodge(0.9), label.padding = unit(0.1, "lines"))
print(p_SOI_allq_Env)
View(SOI_allq_Env)
# Plot results - Work Environment - basic plot
p_SOI_allq_Env<- ggplot(SOI_allq_Env, aes(x=variable, y=Mean, fill=SurveyYear.f)) +
geom_bar(stat="identity", color="black",
position=position_dodge()) +
geom_errorbar(aes(ymin=Mean-2*SD, ymax=Mean+2*SD), width=.2,
position=position_dodge(.9))
# Cleaned up bar plot
p_SOI_allq_Env <- p_SOI_allq_Env+labs(title="Work Environment Average Scores, Mean & 95% Confidence Interval", x="Survey Question", y = "Average Score")+
theme_minimal()+scale_fill_discrete(name = "Survey Year") +
theme(axis.text.x=element_text(angle=40, hjust=1, size = 7))+
geom_label(data = SOI_allq_Env, aes(x=variable, y=Mean-1, label=round(Mean, digits=2)), position = position_dodge(0.9), label.padding = unit(0.1, "lines"))
print(p_SOI_allq_Env)
## Setup ##
# Import packages
library(readxl)
library(broom)
library(tibble)
library(ggplot2)
library(reshape2)
library(scales)
library(magrittr)
library(stringi)
library(dplyr)
library(tidyr)
# set directory to GitHub repo
setwd("C:/Users/bjr21/Documents/GitHub/DunnEES")
# set number of years
years <- c("2015","2016","2017")
## Import & clean files ##
df_2017 <- read_excel("2017EESStats.xlsx", sheet=3)
df_2016 <- read_excel("2016EESStats.xlsx", sheet=4)
df_2015 <- read_excel("2015EESStats.xlsx", sheet=2)
# Clean & combine
#This code makes the column names R-friendly for later manipulation. It also selects a subset of the data in 'keeps' to use for analysis
#and converts 'keeps' into 'comps' (short for composites), a dataframe instead of a tibble. 'comps' will be combined into a full set of data later.
names(df_2017)[2] <- "Sex"
names(df_2017)[3] <- "Race"
names(df_2017)[4] <- "OtherRace"
names(df_2017)[5] <- "Tenure"
names(df_2017)[6] <- "Union"
names(df_2017)[7] <- "Agency"
names(df_2017)[8] <- "OtherAgency"
names(df_2017)[136] <- "RetentionComp"
names(df_2017)[141] <- "TalentComp"
names(df_2017)[150] <- "EnviroComp"
names(df_2017)[159] <- "EvalComp"
names(df_2017)[165] <- "CustomerComp"
names(df_2017)[172] <- "UnitComp"
names(df_2017)[179] <- "SuperComp"
names(df_2017)[187] <- "LeaderComp"
names(df_2017)[188] <- "StateComp"
keeps_2017 <- c("SurveyYear", "Sex", "Race", "Tenure", "Union", "Agency", "RetentionComp", "TalentComp", "EnviroComp", "EvalComp", "CustomerComp", "UnitComp", "SuperComp", "LeaderComp", "StateComp")
comps_2017 <- df_2017[keeps_2017]
comps_2017 <- comps_2017[rowSums(is.na(comps_2017))!=ncol(comps_2017), ] #drops the values where all responses are null (e.g. someone only answered the open responses)
names(df_2016)[2] <- "Sex"
names(df_2016)[3] <- "Race"
names(df_2016)[4] <- "OtherRace"
names(df_2016)[5] <- "Tenure"
names(df_2016)[6] <- "Union"
names(df_2016)[7] <- "Agency"
names(df_2016)[8] <- "OtherAgency"
names(df_2016)[130] <- "RetentionComp"
names(df_2016)[135] <- "TalentComp"
names(df_2016)[144] <- "EnviroComp"
names(df_2016)[153] <- "EvalComp"
names(df_2016)[159] <- "CustomerComp"
names(df_2016)[166] <- "UnitComp"
names(df_2016)[173] <- "SuperComp"
names(df_2016)[181] <- "LeaderComp"
names(df_2016)[182] <- "StateComp"
keeps_2016 <- c("SurveyYear", "Sex", "Race", "Tenure", "Union", "Agency", "RetentionComp", "TalentComp", "EnviroComp", "EvalComp", "CustomerComp", "UnitComp", "SuperComp", "LeaderComp", "StateComp")
comps_2016 <- df_2016[keeps_2016]
comps_2016 <- comps_2016[rowSums(is.na(comps_2016))!=ncol(comps_2016), ]
names(df_2015)[2] <- "Sex"
names(df_2015)[3] <- "Race"
names(df_2015)[4] <- "Tenure"
names(df_2015)[6] <- "Union"
names(df_2015)[7] <- "Agency"
names(df_2015)[126] <- "RetentionComp"
names(df_2015)[131] <- "TalentComp"
names(df_2015)[140] <- "EnviroComp"
names(df_2015)[149] <- "EvalComp"
names(df_2015)[155] <- "CustomerComp"
names(df_2015)[162] <- "UnitComp"
names(df_2015)[169] <- "SuperComp"
names(df_2015)[177] <- "LeaderComp"
names(df_2015)[179] <- "StateComp"
keeps_2015 <- c("SurveyYear", "Sex", "Race", "Tenure", "Union", "Agency", "RetentionComp", "TalentComp", "EnviroComp", "EvalComp", "CustomerComp", "UnitComp", "SuperComp", "LeaderComp", "StateComp")
comps_2015 <- df_2015[keeps_2015]
comps_2015 <- comps_2015[rowSums(is.na(comps_2015))!=ncol(comps_2015), ]
# make into one large dataset
fullset <- rbind(comps_2015, comps_2016, comps_2017) #combines the subsets of each year into a subset of all years.
fullset$Sex <- factor(fullset$Sex) #makes factor variables for earier manipulation later
fullset$Race <- factor(fullset$Race)
fullset$Tenure <- factor(fullset$Tenure)
fullset$Union <- factor(fullset$Union)
fullset$SurveyYear.f <- factor(fullset$SurveyYear)
fullset$Agency <- factor(fullset$Agency)
# keep only the results that have at least some survey answers
fullset <- drop_na(fullset, "StateComp") #because StateComp is a sum of all the other composites, if it is N/A, they must have submitted no numeric answers
## Survey Results Analysis ##
# Calculate aggregate statistics
#melt the dataset so that each composite is on its own line, separated out by all of the ID variables below
fullsetm <- melt(data=fullset, id.vars = c("SurveyYear", "SurveyYear.f", "Sex", "Race", "Tenure", "Union", "Agency"))
#cast the dataset to get the mean and standard deviation across the entire population
fullmean <- dcast(fullsetm, SurveyYear.f + variable ~ ., mean, na.rm=TRUE)
fullsd <- dcast(fullsetm, SurveyYear.f + variable ~ ., sd, na.rm=TRUE)
names(fullmean)[3] <- "Mean"
names(fullsd)[3] <- "SD"
# Bind the mean and standard deviation into one dataset
SOI_results<- cbind(fullmean,fullsd$SD)
names(SOI_results)[4] <- "SD"
SOI_results <- na.omit(SOI_results) #clear out the glitch of the unknown years that melting introduces
SOI_subset_only <-subset(SOI_results, variable!="StateComp") #all of the composite scores except the statewide composite
SOI_state_only <-subset(SOI_results, variable=="StateComp") #only the statewide composite score
# Plot results - basic plot: composite questions
p_SOI_subset_only<- ggplot(SOI_subset_only, aes(x=variable, y=Mean, fill=SurveyYear.f)) +
geom_bar(stat="identity", color="black",
position=position_dodge(0.9)) +
geom_errorbar(aes(ymin=Mean-2*SD, ymax=Mean+2*SD), width=.2,
position=position_dodge(width = 0.9))
# Cleaned up bar plot
p_SOI_subset_only <- p_SOI_subset_only+labs(title="Survey Section Composite Scores, Mean & 95% Confidence Interval", x="Survey Focus", y = "Average Composite Score")+
theme_minimal()+scale_fill_discrete(name = "Survey Year") +
scale_x_discrete(labels=c("Retention & Satisfaction", "Talent Development", "Work Environment", "Worker Evaluations", "Customer Interactions", "Work Unit", "Supervision", "Leadership"))  +
theme(axis.text.x=element_text(angle=30, hjust=1))+
geom_label(data = SOI_subset_only, aes(x=variable, y=Mean-2, label=round(Mean, digits=2)), position = position_dodge(0.9), label.padding = unit(0.1, "lines"))
#print(p_SOI_subset_only)
picname <- "1State_Composites.jpg"
## Determine % change year to year, and whether it is statistically significant ##
# Perform t-test
# use Welch's two-sided test to control for unequal sample sizes
delfull <- subset(fullset,SurveyYear.f==2015 | SurveyYear.f==2017) #delta between start of survey and most recent year
delrecent <- subset(fullset,SurveyYear.f==2016 | SurveyYear.f==2017) #delta between last two runs of the survey
full_ttest <- lapply(delfull[,7:15], function(i) t.test(i ~ delfull$SurveyYear.f)) #lapply produces a vector that applies the function to each column of the input
recent_ttest <- lapply(delrecent[,7:15], function(i) t.test(i ~ delrecent$SurveyYear.f)) #the ttest function tells it that two populations are indicated by the two years
# set vectors for calculating % change - extracts the results from the vector
full_results_end <- c(full_ttest$RetentionComp$estimate[2], full_ttest$TalentComp$estimate[2], full_ttest$EnviroComp$estimate[2], full_ttest$EvalComp$estimate[2],
full_ttest$CustomerComp$estimate[2], full_ttest$UnitComp$estimate[2], full_ttest$SuperComp$estimate[2], full_ttest$LeaderComp$estimate[2],
full_ttest$StateComp$estimate[2])
full_results_beg <- c(full_ttest$RetentionComp$estimate[1], full_ttest$TalentComp$estimate[1], full_ttest$EnviroComp$estimate[1], full_ttest$EvalComp$estimate[1],
full_ttest$CustomerComp$estimate[1], full_ttest$UnitComp$estimate[1], full_ttest$SuperComp$estimate[1], full_ttest$LeaderComp$estimate[1],
full_ttest$StateComp$estimate[1])
rec_results_end <- c(recent_ttest$RetentionComp$estimate[2], recent_ttest$TalentComp$estimate[2], recent_ttest$EnviroComp$estimate[2], recent_ttest$EvalComp$estimate[2],
recent_ttest$CustomerComp$estimate[2], recent_ttest$UnitComp$estimate[2], recent_ttest$SuperComp$estimate[2], recent_ttest$LeaderComp$estimate[2],
recent_ttest$StateComp$estimate[2])
rec_results_beg <- c(recent_ttest$RetentionComp$estimate[1], recent_ttest$TalentComp$estimate[1], recent_ttest$EnviroComp$estimate[1], recent_ttest$EvalComp$estimate[1],
recent_ttest$CustomerComp$estimate[1], recent_ttest$UnitComp$estimate[1], recent_ttest$SuperComp$estimate[1], recent_ttest$LeaderComp$estimate[1],
recent_ttest$StateComp$estimate[1])
# calculate % change. full=2015 to most recent year, while recent should be the most recent year and the prior year
PC_full <- (full_results_end - full_results_beg)/full_results_beg
names(PC_full) <- c("Retention & Satisfaction", "Talent Development", "Work Environment", "Worker Evaluations", "Customer Interactions", "Work Unit", "Supervision", "Leadership", "State Composite")
PC_rec <- (rec_results_end - rec_results_beg)/rec_results_beg
names(PC_rec) <- c("Retention & Satisfaction", "Talent Development", "Work Environment", "Worker Evaluations", "Customer Interactions", "Work Unit", "Supervision", "Leadership", "State Composite")
# Extract statistical significance
full_results_pval <- c(full_ttest$RetentionComp$p.value, full_ttest$TalentComp$p.value, full_ttest$EnviroComp$p.value, full_ttest$EvalComp$p.value,
full_ttest$CustomerComp$p.value, full_ttest$UnitComp$p.value, full_ttest$SuperComp$p.value, full_ttest$LeaderComp$p.value,
full_ttest$StateComp$p.value)
# Translate statistical significance into un-significant, 95% confidence interval, 99% confidence interval
CInul_full <- full_results_pval>0.05
CI95_full <- full_results_pval<=0.05 & full_results_pval>0.01
CI99_full <- full_results_pval<=0.01
# Use the logical variables above to create graphical representations of significance
full_results_pval <- replace(full_results_pval,CI99_full,"**")
full_results_pval <- replace(full_results_pval,CI95_full,"*")
full_results_pval <- replace(full_results_pval,CInul_full," ")
# Repeat the translation of significance for the change in the 'recent' set
rec_results_pval <- c(recent_ttest$RetentionComp$p.value, recent_ttest$TalentComp$p.value, recent_ttest$EnviroComp$p.value, recent_ttest$EvalComp$p.value,
recent_ttest$CustomerComp$p.value, recent_ttest$UnitComp$p.value, recent_ttest$SuperComp$p.value, recent_ttest$LeaderComp$p.value,
recent_ttest$StateComp$p.value)
CInul_rec <- rec_results_pval>0.05
CI95_rec <- rec_results_pval<=0.05 & rec_results_pval>0.01
CI99_rec <- rec_results_pval<=0.01
rec_results_pval <- replace(rec_results_pval,CI95_rec,"*")
rec_results_pval <- replace(rec_results_pval,CInul_rec," ")
rec_results_pval <- replace(rec_results_pval,CI99_rec,"**")
## Plot out question-by-question comparisons ##
# Clean 2015 data
df_2015$`State Average` <- NULL #removes the state average column, aligning the number of question columns across years
names(df_2015) <- replace(names(df_2015),c(120:178),names(df_2017[130:188])) #cleans up different question intro (all the "my coworkers" replaced with "State of Illinois")
allq_fullset <- bind_rows(df_2015[,c(1:4,6:7,120:178)], df_2016[,c(1:3,5:7,124:182)], df_2017[,c(1:3,5:7, 130:188)])
# keep only the results that have at least some survey answers
allq_fullset <- drop_na(allq_fullset, "StateComp")
allq_fullset$`Retention and Satisfaction Average` <- NULL
allq_fullset$`Work Environment Average` <- NULL
allq_fullset$`Worker Evalutions Average` <- NULL
allq_fullset$`Talent Development Average` <- NULL
allq_fullset$`Work Unit Average` <- NULL
allq_fullset$`Supervison Average` <- NULL
allq_fullset$`Customer Interactions Average` <- NULL
allq_fullset$`Leadership Average` <- NULL
allq_fullset$`Worker Evaluations Average` <- NULL
allq_fullset$`Supervision Average` <- NULL
# make data into factors
allq_fullset$Sex <- factor(allq_fullset$Sex)
allq_fullset$Race <- factor(allq_fullset$Race)
allq_fullset$Tenure <- factor(allq_fullset$Tenure)
allq_fullset$Union <- factor(allq_fullset$Union)
allq_fullset$Agency <- factor(allq_fullset$Agency)
allq_fullset$SurveyYear.f <- factor(allq_fullset$SurveyYear)
# melt the dataset for aggregation
allq_fullsetm <- melt(data=allq_fullset, id.vars = c("SurveyYear", "SurveyYear.f", "Sex", "Race", "Tenure", "Union", "Agency"))
# aggregate by year and variable to get mean and standard deviation
allq_fullmean <- dcast(allq_fullsetm, SurveyYear.f + variable ~ ., mean, na.rm=TRUE) #mean
allq_fullsd <- dcast(allq_fullsetm, SurveyYear.f + variable ~ ., sd, na.rm=TRUE) #standard deviation
names(allq_fullmean)[3] <- "Mean"
names(allq_fullsd)[3] <- "SD"
# make into one dataset for plotting
SOI_allq<- cbind(allq_fullmean,allq_fullsd$SD)
names(SOI_allq)[4] <- "SD"
SOI_allq <- na.omit(SOI_allq)
brkpt <-round(stri_length(SOI_allq$variable)/2, digits=0) #add breakpoint for plotting - splits halfway through question
stri_sub(SOI_allq$variable,brkpt+1,brkpt) <- "-\n"
SOI_allq_Ret <- SOI_allq[c(1:5,52:56,103:107),]
SOI_allq_Tal <- SOI_allq[c(7:9,58:60,109:111),]
SOI_allq_Env <- SOI_allq[c(11:17,62:68,113:119),]
SOI_allq_Eval <- SOI_allq[c(19:25,70:76,121:127),]
SOI_allq_Unit <- SOI_allq[c(32:36,83:87,134:138),]
SOI_allq_Cust <- SOI_allq[c(27:30,78:81,129:132),]
SOI_allq_Sup <- SOI_allq[c(38:42,89:93,140:144),]
SOI_allq_Lead <- SOI_allq[c(44:49,95:100,146:151),]
allq_plotting_fun <- function(label_shift, title_in, data_in, picname_in){
# Plot results  - basic plot
p_SOI_allq_gen<- ggplot(data_in, aes(x=variable, y=Mean, fill=SurveyYear.f)) +
geom_bar(stat="identity", color="black",
position=position_dodge()) +
geom_errorbar(aes(ymin=Mean-2*SD, ymax=Mean+2*SD), width=.2,
position=position_dodge(.9))
# Cleaned up bar plot
p_SOI_allq_gen <- p_SOI_allq_gen+labs(title=title_in, x="Survey Question", y = "Average Score")+
theme_minimal()+scale_fill_discrete(name = "Survey Year") +
theme(axis.text.x=element_text(angle=40, hjust=1, size = 7))+
geom_label(data = data_in, aes_string(x=variable, y=Mean-label_shift, label=round(Mean, digits=2)), position = position_dodge(0.9), label.padding = unit(0.1, "lines"))
print(p_SOI_allq_gen)
picname <- picname_in
ggsave(picname, plot = last_plot(), device = "jpeg", path = NULL, width = 12, height = 6, units = "in", dpi = 600, limitsize = TRUE)
return(p_SOI_allq_gen)
}
test_plot <- allq_plotting_fun(label_shift = 1, title_in = "Work Environment Average Scores, Mean & 95% Confidence Interval", data_in = SOI_allq_Env , picname_in = "1Statewide_WorkEnvironment.jpg")
allq_plotting_fun <- function(label_shift, title_in, data_in, picname_in){
# Plot results  - basic plot
p_SOI_allq_gen<- ggplot(data_in, aes(x=variable, y=Mean, fill=SurveyYear.f)) +
geom_bar(stat="identity", color="black",
position=position_dodge()) +
geom_errorbar(aes(ymin=Mean-2*SD, ymax=Mean+2*SD), width=.2,
position=position_dodge(.9))
# Cleaned up bar plot
p_SOI_allq_gen <- p_SOI_allq_gen+labs(title=title_in, x="Survey Question", y = "Average Score")+
theme_minimal()+scale_fill_discrete(name = "Survey Year") +
theme(axis.text.x=element_text(angle=40, hjust=1, size = 7))+
geom_label(data = data_in, aes(x=variable, y=Mean-label_shift, label=round(Mean, digits=2)), position = position_dodge(0.9), label.padding = unit(0.1, "lines"))
print(p_SOI_allq_gen)
picname <- picname_in
ggsave(picname, plot = last_plot(), device = "jpeg", path = NULL, width = 12, height = 6, units = "in", dpi = 600, limitsize = TRUE)
return(p_SOI_allq_gen)
}
allq_plotting_fun <- function(label_shift, title_in, data_in, picname_in){
# Plot results  - basic plot
p_SOI_allq_gen<- ggplot(data_in, aes(x=variable, y=Mean, fill=SurveyYear.f)) +
geom_bar(stat="identity", color="black",
position=position_dodge()) +
geom_errorbar(aes(ymin=Mean-2*SD, ymax=Mean+2*SD), width=.2,
position=position_dodge(.9))
# Cleaned up bar plot
p_SOI_allq_gen <- p_SOI_allq_gen+labs(title=title_in, x="Survey Question", y = "Average Score")+
theme_minimal()+scale_fill_discrete(name = "Survey Year") +
theme(axis.text.x=element_text(angle=40, hjust=1, size = 7))+
geom_label(data = data_in, aes(x=variable, y=Mean-label_shift, label=round(Mean, digits=2)), position = position_dodge(0.9), label.padding = unit(0.1, "lines"))
print(p_SOI_allq_gen)
picname <- picname_in
ggsave(picname, plot = last_plot(), device = "jpeg", path = NULL, width = 12, height = 6, units = "in", dpi = 600, limitsize = TRUE)
return(p_SOI_allq_gen)
}
test_plot <- allq_plotting_fun(label_shift = 1, title_in = "Work Environment Average Scores, Mean & 95% Confidence Interval", data_in = SOI_allq_Env , picname_in = "1Statewide_WorkEnvironment.jpg")
print(test_plot)
# Plot results - Work Environment - basic plot
p_SOI_allq_Env<- ggplot(SOI_allq_Env, aes(x=variable, y=Mean, fill=SurveyYear.f)) +
geom_bar(stat="identity", color="black",
position=position_dodge()) +
geom_errorbar(aes(ymin=Mean-2*SD, ymax=Mean+2*SD), width=.2,
position=position_dodge(.9))
# Cleaned up bar plot
p_SOI_allq_Env <- p_SOI_allq_Env+labs(title="Work Environment Average Scores, Mean & 95% Confidence Interval", x="Survey Question", y = "Average Score")+
theme_minimal()+scale_fill_discrete(name = "Survey Year") +
theme(axis.text.x=element_text(angle=40, hjust=1, size = 7))+
geom_label(data = SOI_allq_Env, aes(x=variable, y=Mean-1, label=round(Mean, digits=2)), position = position_dodge(0.9), label.padding = unit(0.1, "lines"))
print(p_SOI_allq_Env)
# Plot results - Talent Development - basic plot
p_SOI_allq_Tal<- ggplot(SOI_allq_Tal, aes(x=variable, y=Mean, fill=SurveyYear.f)) +
geom_bar(stat="identity", color="black",
position=position_dodge()) +
geom_errorbar(aes(ymin=Mean-2*SD, ymax=Mean+2*SD), width=.2,
position=position_dodge(.9))
# Cleaned up bar plot
p_SOI_allq_Tal <- p_SOI_allq_Tal+labs(title="Talent Development Average Scores, Mean & 95% Confidence Interval", x="Survey Question", y = "Average Score")+
theme_minimal()+scale_fill_discrete(name = "Survey Year") +
theme(axis.text.x=element_text(angle=15, hjust=1))+
geom_label(data = SOI_allq_Tal, aes(x=variable, y=Mean-0.5, label=round(Mean, digits=2)), position = position_dodge(0.9), label.padding = unit(0.1, "lines"))
print(p_SOI_allq_Tal)
## Setup ##
# Import packages
library(readxl)
library(broom)
library(tibble)
library(ggplot2)
library(reshape2)
library(scales)
library(stringi)
library(magrittr)
library(dplyr)
library(tidyr)
# set directory to GitHub repo
setwd("C:/Users/bjr21/Documents/GitHub/DunnEES")
# set number of years
years <- c("2015","2016","2017")
## Import & clean files ##
df_2017 <- read_excel("2017EESStats.xlsx", sheet=3)
df_2016 <- read_excel("2016EESStats.xlsx", sheet=4)
df_2015 <- read_excel("2015EESStats.xlsx", sheet=2)
# Clean & combine
#This code makes the column names R-friendly for later manipulation. It also selects a subset of the data in 'keeps' to use for analysis
#and converts 'keeps' into 'comps' (short for composites), a dataframe instead of a tibble. 'comps' will be combined into a full set of data later.
names(df_2017)[2] <- "Sex"
names(df_2017)[3] <- "Race"
names(df_2017)[4] <- "OtherRace"
names(df_2017)[5] <- "Tenure"
names(df_2017)[6] <- "Union"
names(df_2017)[7] <- "Agency"
names(df_2017)[8] <- "OtherAgency"
names(df_2017)[136] <- "RetentionComp"
names(df_2017)[141] <- "TalentComp"
names(df_2017)[150] <- "EnviroComp"
names(df_2017)[159] <- "EvalComp"
names(df_2017)[165] <- "CustomerComp"
names(df_2017)[172] <- "UnitComp"
names(df_2017)[179] <- "SuperComp"
names(df_2017)[187] <- "LeaderComp"
names(df_2017)[188] <- "StateComp"
keeps_2017 <- c("SurveyYear", "Sex", "Race", "Tenure", "Union", "Agency", "RetentionComp", "TalentComp", "EnviroComp", "EvalComp", "CustomerComp", "UnitComp", "SuperComp", "LeaderComp", "StateComp")
comps_2017 <- df_2017[keeps_2017]
comps_2017 <- comps_2017[rowSums(is.na(comps_2017))!=ncol(comps_2017), ] #drops the values where all responses are null (e.g. someone only answered the open responses)
names(df_2016)[2] <- "Sex"
names(df_2016)[3] <- "Race"
names(df_2016)[4] <- "OtherRace"
names(df_2016)[5] <- "Tenure"
names(df_2016)[6] <- "Union"
names(df_2016)[7] <- "Agency"
names(df_2016)[8] <- "OtherAgency"
names(df_2016)[130] <- "RetentionComp"
names(df_2016)[135] <- "TalentComp"
names(df_2016)[144] <- "EnviroComp"
names(df_2016)[153] <- "EvalComp"
names(df_2016)[159] <- "CustomerComp"
names(df_2016)[166] <- "UnitComp"
names(df_2016)[173] <- "SuperComp"
names(df_2016)[181] <- "LeaderComp"
names(df_2016)[182] <- "StateComp"
keeps_2016 <- c("SurveyYear", "Sex", "Race", "Tenure", "Union", "Agency", "RetentionComp", "TalentComp", "EnviroComp", "EvalComp", "CustomerComp", "UnitComp", "SuperComp", "LeaderComp", "StateComp")
comps_2016 <- df_2016[keeps_2016]
comps_2016 <- comps_2016[rowSums(is.na(comps_2016))!=ncol(comps_2016), ]
names(df_2015)[2] <- "Sex"
names(df_2015)[3] <- "Race"
names(df_2015)[4] <- "Tenure"
names(df_2015)[6] <- "Union"
names(df_2015)[7] <- "Agency"
names(df_2015)[126] <- "RetentionComp"
names(df_2015)[131] <- "TalentComp"
names(df_2015)[140] <- "EnviroComp"
names(df_2015)[149] <- "EvalComp"
names(df_2015)[155] <- "CustomerComp"
names(df_2015)[162] <- "UnitComp"
names(df_2015)[169] <- "SuperComp"
names(df_2015)[177] <- "LeaderComp"
names(df_2015)[179] <- "StateComp"
keeps_2015 <- c("SurveyYear", "Sex", "Race", "Tenure", "Union", "Agency", "RetentionComp", "TalentComp", "EnviroComp", "EvalComp", "CustomerComp", "UnitComp", "SuperComp", "LeaderComp", "StateComp")
comps_2015 <- df_2015[keeps_2015]
comps_2015 <- comps_2015[rowSums(is.na(comps_2015))!=ncol(comps_2015), ]
# make into one large dataset
fullset <- rbind(comps_2015, comps_2016, comps_2017) #combines the subsets of each year into a subset of all years.
fullset$Sex <- factor(fullset$Sex) #makes factor variables for earier manipulation later
fullset$Race <- factor(fullset$Race)
fullset$Tenure <- factor(fullset$Tenure)
fullset$Union <- factor(fullset$Union)
fullset$Agency <- factor(fullset$Agency)
fullset$SurveyYear.f <- factor(fullset$SurveyYear)
# keep only the results that have at least some survey answers
fullset <- drop_na(fullset, "StateComp") #because StateComp is a sum of all the other composites, if it is N/A, they must have submitted no numeric answers
## Survey Results Analysis ##
# Calculate aggregate statistics
#melt the dataset so that each composite is on its own line, separated out by all of the ID variables below
fullsetm <- melt(data=fullset, id.vars = c("SurveyYear", "SurveyYear.f", "Sex", "Race", "Tenure", "Union", "Agency"))
#cast the dataset to get the mean and standard deviation across the entire population
fullmean <- dcast(fullsetm, SurveyYear.f + variable ~ ., mean, na.rm=TRUE)
fullsd <- dcast(fullsetm, SurveyYear.f + variable ~ ., sd, na.rm=TRUE)
names(fullmean)[3] <- "Mean"
names(fullsd)[3] <- "SD"
# Bind the mean and standard deviation into one dataset
SOI_results<- cbind(fullmean,fullsd$SD)
names(SOI_results)[4] <- "SD"
SOI_results <- na.omit(SOI_results) #clear out the glitch of the unknown years that melting introduces
SOI_state_only <-subset(SOI_results, variable=="StateComp") #only the statewide composite score
SOI_subset_only <-subset(SOI_results, variable!="StateComp") #all of the composite scores except the statewide composite
# Plot results - basic plot: composite questions
p_SOI_subset_only<- ggplot(SOI_subset_only, aes(x=variable, y=Mean, fill=SurveyYear.f)) +
geom_bar(stat="identity", color="black",
position=position_dodge(0.9)) +
geom_errorbar(aes(ymin=Mean-2*SD, ymax=Mean+2*SD), width=.2,
position=position_dodge(width = 0.9))
# Cleaned up bar plot
p_SOI_subset_only <- p_SOI_subset_only+labs(title="Survey Section Composite Scores, Mean & 95% Confidence Interval", x="Survey Focus", y = "Average Composite Score")+
theme_minimal()+scale_fill_discrete(name = "Survey Year") +
scale_x_discrete(labels=c("Retention & Satisfaction", "Talent Development", "Work Environment", "Worker Evaluations", "Customer Interactions", "Work Unit", "Supervision", "Leadership"))  +
theme(axis.text.x=element_text(angle=30, hjust=1))+
geom_label(data = SOI_subset_only, aes(x=variable, y=Mean-2, label=round(Mean, digits=2)), position = position_dodge(0.9), label.padding = unit(0.1, "lines"))
print(p_SOI_subset_only)
